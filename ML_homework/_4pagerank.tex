

\chapter{PageRank算法}
\indent Google采用``网页级别（PageRank）''与``页面分析''两种技术来确保检索质量与精确率。所谓PageRank技术是基于整个网络的链接结构，按网页的链接广度（Link Popularity）来决定网页重要性。而``页面分析''则按页面标题是否出现关键词、网页内关键词出现的频率（keyword density）及关键词出现在什么位置等，来确定哪些网页与正在执行的搜索密切相关。这里重点讲述前者的数学机制。
\section{PageRank算法}
\indent 传统的搜索异于互联网搜索的特点：
\begin{enumerate}
  \item 搜索对象的数量较小\raisebox{0.5mm}{------}比如一本字典收录的字通常只有一两万个，一家图书馆收录的不重复图书通常不超过几十万种，一家商店的商品通常不超过几万种。
  \item 搜索对象具有良好的分类或排序\raisebox{0.5mm}{------}比如字典里的字按拼音排序，图书馆里的图书按主题分类，商店里的商品按品种或用途分类等等。
  \item 搜索结果的重复度较低\raisebox{0.5mm}{------}比如字典里的同音字通常不超过几十个，图书馆里的同名图书和商店里的同种商品通常也不超过几十种。
\end{enumerate}

\indent 对于互联网搜索的前两个特点，可以分别通过增加服务器计算能力和存储空间的手段来解决，而对于第三个特点，就只能事先就知道搜索结果的重要性的排序，并把排名靠前的结果优先展示给用户。

\indent 每个网页的排序是不能靠网页自己来控制的， 例如一个垃圾网页无论把关键词重复多少次， 它仍然是垃圾网页，用户在搜索该关键词时该网页的排序仍然是要靠后的。

\indent 学术界评判学术论文重要性的通用方法， 那就是看论文的引用次数。在互联网上， 与论文的引用相类似的是显然是网页的链接，那么通过研究网页间的相互链接来确定排序或许也是一种思路。实际上，PageRank也是这么做的。 具体地说，一个网页被其它网页链接得越多， 它的排序就应该越靠前。 不仅如此，一个网页越是被排序靠前的网页所链接， 它的排序就也应该越靠前。 这一条的意义也是不言而喻的， 就好比一篇论文被诺贝尔奖得主所引用， 显然要比被普通研究者所引用更说明其价值。

\indent 首先我们阐述两个相关的概念：
\begin{enumerate}
  \item 网页$i$的入链(in-links)：那些指向网页$i$的来自于其它网页的超链接，通常不包括来自于同一站点内网页的超链接。
  \item 网页$i$的出链(out-links)：那些从网页$i$指向其它网页的超链接，通常不包括指向同一站点内网页的超链接。
\end{enumerate}

\indent 前面从论文引用的角度阐述了PageRank的思想，现在我们从排序声望(rank prestige)的角度进行进一步阐述：
\begin{enumerate}
  \item 从一个网页指向另一网页的超链接是PageRank值的隐含式传递，网页的PageRank值是由指向它的所有的网页所传递过来的PageRank值总和决定的。这样，网页$i$的入链越多，它的PageRank值可能就越高，它得到的声望也就越高。
  \item 一个网页指向多个其他网页，那么它传递的声望值就会被它所指向的多个网页分享。也就是说，即使网页$i$被一个PageRank值很高的网页$j$所指向，如果网页$j$的出链非常多，网页$i$从网页$j$得到的声望值可能因被稀释也很小。
\end{enumerate}
\indent 我们可以把Web抽象成一个有向图$G=(V,E)$,其中$V$是图的节点集合(一个节点对应一个网页),$E$是图的有向边集合(有向边对应超链接)。设Web上的网页总数为$n$(即，$n=\mid\negthickspace V\negthickspace\mid$)。上述思想可以形式化为：
\begin{equation*}
  P(i)=\sum_{(j,i)\in E}\frac{P(j)}{O_j}
\end{equation*}
\indent 其中$P(i)$表示网页$i$的PageRank值，$O_j$是网页$j$出链的数量，$(j,i)\in E$表示存在网页$j$指向网页$i$的超链接。从数学的观点看就存在一个包含$n$个未知量的线性方程组，可以用一个矩阵来表示。首先作一个符号的约定，用列向量$\bm{P}$表示$n$个网页的的PageRank 值，如下：
\begin{equation*}
  \bm{P}=\left(P(1),P(2),\cdots,P(n)\right)^T
\end{equation*}
再用矩阵A表示有向图的邻接矩阵，并按如下规则为每条有向边赋值：
\begin{eqnarray*}
\bm{A}_{ij}=
  \begin{cases}
    \frac{1}{O_i}\!&\mathrm{if}(i,j)\in E \\
    0\!&\mathrm{else}
  \end{cases}
\end{eqnarray*}
比如下面的网络链接结构图
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{network.jpg}
    \caption{网络的超链接图的例子}
    \label{fig:network}
\end{figure}
其对应的邻接矩阵$\bm{A}$如下：\\
\begin{center}$\bm{A}$=$\begin{pmatrix}
0 & \frac{1}{2} & \frac{1}{2}   &0  &0  &0 \\
\frac{1}{2} & 0 & \frac{1}{2}   &0  &0  &0 \\
0 & 1 & 0 &0  &0  &0 \\
0 & 0 & \frac{1}{3}   &0  &\frac{1}{3}  &\frac{1}{3} \\
0 & 0 & 0   &0  &0  &0 \\
0 & 0 & 0   &\frac{1}{2}  &\frac{1}{2} &0
\end{pmatrix}$ \end{center}

\indent 我们可以得到如下方程组：
\begin{equation}
  \bm{P}=\bm{A}^T\bm{P}
\end{equation}
\indent 我们的任务就是在已知矩阵$\bm{A}$的条件下,求解向量$\bm{P}$。再看方程组，发现$\bm{P}$是循环定义的，所以看以用著名的幂迭代方法求解$\bm{P}$。
我们定义可以给定初值$\bm{P}_0$，定义$\bm{P}_n$是经过第$n$次迭代得到的$\bm{P}$值，则可以形式化如下：
\begin{equation}
  \begin{split}
    \bm{P}_{n+1}=\bm{A}^T\bm{P}_n\qquad,n=0,1,\cdots,\infty,\mathrm{given}~ \bm{P}_0
  \end{split}
\end{equation}
满足公式(1)方程组的解$\bm{P}^{*}$就是$\lim\limits_{n\rightarrow \infty}\bm{P}_{n}$。
\\ \indent 当然,也可以用马尔科夫链(Markov chain)进行建模，这时 $\bm{P}_{n}$ 就可以看成是Markov chain的一个状态(state),$\bm{A}$ 可以表示状态转移矩阵(state transition matrix), 这样就可以转换成马尔科夫链的遍历性和极限分布问题。
\\ \indent 接下来我们要处理的问题就是：
\begin{enumerate}
  \item $\lim\limits_{n\rightarrow \infty}\bm{P}_{n}$是否存在？
  \item 如果极限存在，它是否与$\bm{P}_0$的选取无关？
  \item 如果极限存在，并且与$\bm{P}_0$的选取无关，它作为网页排序的依据是否真的合理？
\end{enumerate}

\indent 如果这三个问题的答案都是肯定的,那么网页排序问题就算解决了。反之，哪怕只有一个问题的答案是否定的，网页排序问题也就不能算是得到了满意解决。那么实际答案如何呢?很遗憾,是后一种，而且三个问题的答案全都是否定的。 这可以由一些简单的例子看出。比方说， 在只包含两个相互链接网页的迷你型互联网上， 如果$P_0=\left(1,0\right)^T$，极限就不存在 ,因为概率分布将在$\left(1,0\right)^T$和$\left(0,1\right)^T$之间无穷振荡。而存在几个互不连通 (即互不链接) 区域的互联网则会使极限――即便存在―― 与$P_0$的选取有关，因为把$P_0$ 选在不同区域内显然会导致不同极限。 至于极限存在，并且与$P_0$的选取无关时它作为网页排序的依据是否真的合理的问题，虽然不是数学问题，答案却也是否定的， 因为任何一个``悬挂网页''都能象黑洞一样， 把其它网页的概率 “吸收” 到自己身上而不再向外``释放''，这显然是不合理的。这种不合理效应是如此显著， 以至于在一个连通性良好的互联网上， 哪怕只有一个 `` 悬挂网页''， 也足以使整个互联网的网页排序失效。
\\indent 在进一步讨论之前，我们引入几个概念：
\begin{itemize}
  \item 正矩阵(Positive matrix):每个矩阵元都大于0的矩阵。每个元素都大于等于0的矩阵是非负矩阵(Nonnegative matrix).
  \item 素阵(Primitive matrix)：素矩阵是指自身的某个次幂为正矩阵(Positive matrix)的矩阵。设$\bm{A}$为一个$n\times n$的方阵, 如果存在正整数$k$ 使得矩阵
      \begin{equation*}
        \bm{A}^k>0
      \end{equation*}
      那么, 称矩阵$\bm{A}$为素矩阵。
  \item 随机矩阵(stochastic matrix)：随机矩阵又叫概率矩阵（probability matrix）、转移矩阵（transition matrix）、马尔科夫矩阵（Markov matrix）等。随机矩阵通常表示左随机矩阵(left stochastic matrix)，如果方矩阵$\bm{A}_{n\times n}$为（左）随机矩阵，则其满足以下条件：
      \begin{equation*}
        \begin{split}
        \mathrm{suppose~}&a_{i,j}  \mathrm{~is~the~element~from~}\bm{A} \mathrm{~at~row~} i ,\mathrm{~colomn~} j,\mathrm{then~we~have~}\\
          &\forall i=1..n, j=1..n,a_{i,j}\geq 0\\
          &\forall i=1..n,\sum_{j=1}^{n}a_{ij}=1\\
        \end{split}
      \end{equation*}
      左随机矩阵的转置称为右随机矩阵(right stochastic matrix)。
  \item 不可约矩阵（irreducible matrix）：方阵$\bm{A}$是不可约的当且仅当与矩阵$\bm{A}$对应的有向图是{\bf 强连通}的。有向图$G=(V,E)$是强连通的当且仅当对每一节点对$u,v\in V$，存在从$u$到$v$的路径。也就是说，如果某状态转移矩阵不可约，则其每个状态都可来自任意的其它状态。
  \item 周期图（Periodicity）：说状态$i$是周期的并且具有周期$k>1$，是指存在一个最小的正整数$k$，使得从状态$i$出发又回到状态$i$的{\bf 所有}路径的长度都是$k$的整数倍。如果一个状态不是周期的或者$k=1$，那它就是非周期的。如果一个马尔科夫链的所有状态都是非周期的，那么就说这个马尔科夫链是非周期的。
      下图所示，从状态1出发回到状态1的路径只有一条1-2-3-1，需要的转移次数是3，所以这是一个周期为3的马尔科夫链。
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{period.jpg}
        \caption{周期为3的马尔科夫链}
    \end{figure}
\end{itemize}

\indent 现在回到我们前边提出的3个问题。这里能够给前两个问题以肯定回答（也就是$\lim\limits_{n\rightarrow \infty}\bm{P}_{n}$ 存在且与初值$\bm{P}_0$的选取无关）的转移矩阵$\bm{A}$应该满足的3个条件：
\begin{enumerate}
  \item $\bm{A}$必须是随机矩阵
  \item $\bm{A}$必须是不可约的
  \item $\bm{A}$必须是非周期的
\end{enumerate}

\indent 现在我们来考察一下图\ref{fig:network}能否满足上述条件。我们首先来分析第一个条件是否一定成立？答案是否，即$\bm{A}$不是随机（转移）矩阵，因为$\bm{A}$的第五行的和是0。 究其原因，是因为节点5没有出链，节点5代表的网页叫做悬挂网页。互联网上的悬挂网页是很多的，所以我们需要对$\bm{A}$中代表悬挂网页的行进行修正。怎么修正呢？我们可以从悬挂网页$i$ 向每一个网页（包括它自己）引一条链接，就可以解决这个问题。再具体些，将网页$i$到每个网页的转换概率都设为$\frac{1}{n}$,相当于均匀分布。
\\\indent 我们引进一个含有$n$个元素的列向量作为悬挂网页的指标向量(indicator vector) $\bm{a}$，其第$i$个元素取值视第$i$个网页是否为悬挂网页而定，具体地，为悬挂网页取1，否则取0，另外定义一个含有$n$个元素的单位列向量$\bm{e}$,则上述思想可以形式化为
\begin{equation}
  \bm{S}\leftarrow \bm{A}+\frac{\bm{a}\bm{e}^T}{n}
\end{equation}

\indent 对图\ref{fig:network}的转移矩阵做上述修正后的转移矩阵如下：
\\\begin{center}$\bm{S}$=$\begin{pmatrix}
0 & \frac{1}{2} & \frac{1}{2}   &0  &0  &0 \\
\frac{1}{2} & 0 & \frac{1}{2}   &0  &0  &0 \\
0 & 1 & 0 &0  &0  &0 \\
0 & 0 & \frac{1}{3}   &0  &\frac{1}{3}  &\frac{1}{3} \\
\frac{1}{6} & \frac{1}{6} & \frac{1}{6}   &\frac{1}{6}  &\frac{1}{6}  &\frac{1}{6}\\
0 & 0 & 0   &\frac{1}{2}  &\frac{1}{2} &0
\end{pmatrix}$ \end{center}

\indent 解决了悬挂网页的问题后，我们分析$\bm{S}$是否一定满足第二、第三个条件呢？很容易就可以给予否定。好在我们仅仅用一个策略就可以同时解决这两个问题，将矩阵$\bm{S}$ 改造成不可约和非周期的矩阵。

\indent 对矩阵$\bm{S}$修正如下：
\begin{equation}
  \bm{G}\leftarrow \alpha \bm{S} + (1-\alpha)\frac{\bm{e}\bm{e}^T}{n}
\end{equation}

\indent 其中$\bm{e}$是含有$n$个元素的单位列向量，参数$0<\alpha<1$ ,也称阻尼因子，一般取值0.85。
\\\indent 经过公式(3)、(4)的两步修正，我们就把转移矩阵$\bm{A}$改造成了随机的、不可约的、非周期的转移矩阵$\bm{G}$，这保证了$\lim\limits_{n\rightarrow \infty}\bm{P}_{n}$ 存在且与初值$\bm{P}_0$的选取无关。
\\\indent 继续上面的例子，得到$\bm{G}$如下（$\alpha=0.85$）:
\begin{center}$\bm{G}$=$\begin{pmatrix}
0.0250 & 0.4500 & 0.4500 & 0.0250 & 0.0250 & 0.0250 \\
0.4500 & 0.0250 & 0.4500 & 0.0250 & 0.0250 & 0.0250\\
0.0250 & 0.8750 & 0.0250 & 0.0250 & 0.0250 & 0.0250\\
0.0250 & 0.0250 & 0.3083 & 0.0250 & 0.3083 & 0.3083\\
0.1667 & 0.1667 & 0.1667 & 0.1667 & 0.1667 & 0.1667\\
0.0250 & 0.0250 & 0.0250 & 0.4500 & 0.4500 & 0.0250\\
\end{pmatrix}$ \end{center}

\indent 上述对转移矩阵的两步修正的过程确保了PageRank算法在数学上的可行性，然而这是不够的，我们必须对其作出现实意义的解释，这样才能确保我们之前提出的第三个问题，即``网页排序的依据是否真的合理?''。\\
\indent 接下来我们依次对这两个过程进行分析，即对公式(3)、(4)进行解释：
\begin{itemize}
\item {\bf 对公式(3)的解释}：\\
当互联网用户访问到``悬挂网页''时，不可能``在一棵树上吊死''， 而是会自行访问其它网页。对于单个用户来说，自行访问的网页显然与个人兴趣有关，但对于无数的互联网用户的整体来说，自行访问哪个网页完全是随机的。 用数学语言来说， 这相当于是把转移矩阵$\bf{A}$中代表悬挂网页的行向量的所有的零向量都换成$\frac{{\bf e}}{n}$(其中${\bf e}$是所有分量都为$1$ 的行向量，$n$ 为互联网上的网页总数)。用数学语言表达就是公式(3)。
\item {\bf 对公式(4)的解释}：\\
互联网用户是由一个个活生生的人组成的，他们多少都有自己的``性格'',不会完全受当前网页所限，死板地只访问其所提供的链接。 具体地说， 他们假定虚拟用户在每一步都有一个小于$1$ 的几率 $\alpha$访问当前网页所提供的链接，同时却也有一个几率$1-\alpha$不受那些链接所限，随机访问互联网上的任何一个网站。用数学语言表达就是公式(4)。
\end{itemize}

\indent 通过对公式(3)、(4)的现实意义的解释，我们得到了这样的结论：{\bf 转移矩阵$\bm{G}$不但对网页排名的计算提供了数学上的可行的保证，而且它的推导过程具有对应的真实应用场景的强力支撑}。

\indent 把公式(4)中$\bm{G}$的表达式替代公式(1)、(2)中的A,得到如下的两个公式：
\begin{equation}
  \bm{P}=\left[\alpha\left(\bm{A}^T+\frac{\bm{e}\bm{a}^T}{n}\right)+(1-\alpha)\frac{\bm{e}\bm{e}^T}{n}\right]\bm{P}
\end{equation}
\begin{equation}
  \begin{split}
    \bm{P}_{n+1}=\left[\alpha\left(\bm{A}^T+\frac{\bm{e}\bm{a}^T}{n}\right)+(1-\alpha)\frac{\bm{e}\bm{e}^T}{n}\right]\bm{P}_n,n=0,1,\cdots,\infty,\mathrm{given}~ \bm{P}_0
  \end{split}
\end{equation}
\indent 到这一步之后，摆在我们前面的唯一问题，就是求解了，具体的，确定公式(5)的$\bm{P}$或者与之等价的公式(6)的$\lim\limits_{n\rightarrow \infty}\bm{P}_{n}$。

\indent 用幂迭代法求解的算法很简单，可以赋予任意的PageRank初始值，每迭代依次PageRank值被修正依次，当PageRank值不再显著变化或者趋近收敛时，迭代算法结束。下面的算法的结束条件是插值向量的一阶范数小于一个预设定的阈值$\epsilon$后就结束算法迭代。

  \begin{algorithm}[htb]
  \caption{PageRank-Iterate(G).}
  \begin{algorithmic}[1]
    \STATE $P_0\leftarrow \bm{e}/n$
    \STATE $k\leftarrow 1$
    \REPEAT
    \STATE $\bm{P}_{k+1}=\left[\alpha\left(\bm{A}^T+\frac{\bm{e}\bm{a}^T}{n}\right)+(1-\alpha)\frac{\bm{e}\bm{e}^T}{n}\right]\bm{P}_k$
    \STATE $k\leftarrow k+1$
    \UNTIL $\parallel\negthickspace P_k-P_{k+1}\negthickspace\parallel_1<\epsilon$
    \RETURN $P_k$
  \end{algorithmic}
\end{algorithm}

\indent 公式(6),即$\bm{P}_{k+1}=\bm{G}\bm{P}_k$的平稳分布(即PageRank值)是转移概率矩阵$\bm{G}$的最大特征值$(=1)$所对应的特征向量,它对矩阵扰动的敏感性，依赖于它与其它特征值的分离度。若阻尼因子$\alpha$值靠近$1$，矩阵$\bm{G}$的次特征值会随之靠近$1$，从而导致PageRank对$\alpha$值得选择敏感依赖，计算特征向量算法的收敛速度会降低。也就是说，阻尼因子$\alpha$越小，收敛速度越快。但$\alpha$也不能太小， 因为太小的话，``PageRank''中最精华的部分， 即以网页间的彼此链接为基础的排序思路就被弱化了 (因为这部分的贡献正比于$\alpha$)， 这显然是得不偿失的。 因此， 在$\alpha$的选取上有很多折衷的考虑要做， 佩奇和布林最终选择的数值是 α = 0.85。
\section{PageRank的扩展：Timed-PageRank}
互联网上的新网页不断增加，同时不断地有旧的网页变得过时，然而这些旧的网页很多都不会删掉，这会给搜索带来麻烦，因为这些过时的网页往往在过去的长时间里积累了大量入链从而排序很高，而那些载有新信息的高质量新页面却因为没有足够的入链而排序偏低。
\\\indent 为了应对这种情况，Timed-PageRank算法在PageRank算法基础上增加了一个时间维度，它的思想其实很简单，主干上仍然是沿用PageRank的随机上网和马尔科夫链模型，不同之处在于Timed-PageRank不再适用常量阻尼因子$\alpha$，而是引入一个时间递减函数$f(t)(0\leq f(t)\leq 1)$来``惩罚''过时的网页（此处的t是指当前时间和网页上次更新时间的差值）。函数$f(t)$被定义为点击网页上链接的概率，$1-f(t)$就是不借助网页上的链接而直接跳到一个随机选择的外部网页的概率。那么对于一个特定的网页$i$，有两种选择：
\begin{itemize}
  \item 以$f(t)$的概率随机选择一个外链跳出。
  \item 以$1-f(t)$的概率不通过链接跳到某个随机网页。
\end{itemize}

\section{PerronCFrobenius 定理}
\indent 设$\bm{A}=\left(a_{ij}\right)$为一个$n\times n$的正矩阵：$\forall 1\leq i,j\leq n,a_{ij}>0$，则该矩阵有以下性质：
\begin{enumerate}
  \item $\bm{A}$存在一个正实数的特征值$\lambda^{*}$，叫做Perron根或者PerronCFrobenius特征值，使得其它所有特征值(包括复数特征值)的模都比它小。
  \item $\lambda^{*}$只对应一个特征向量$\bm{v}$。
  \item $\lambda^{*}$所对应的特征向量$\bm{v}$的所有元素都为正实数。
  \item $\lambda^{*}$以外的其它特征值所对应的特征向量的元素至少有一个为负数或复数。
  \item $\lim_{k \rightarrow \infty} \frac{\bm{A}^k\bm{e}}{{\lambda^{*}}^k}= \bm{v}$
  \item $\min\limits_i \sum\limits_{j} a_{ij} \le \lambda^{*} \le \max\limits_i \sum\limits_{j} a_{ij}$
\end{enumerate}
\begin{thebibliography}{9}
\bibitem{}{卢昌海},{谷歌背后的数学}, \url{http://www.changhai.org/articles/technology/misc/google_math.php}, 12/05 2010.
\bibitem{}{姜启源,谢金星},{数学建模案例选集}.
\bibitem{}{Cannel\_2020},{Google搜索引擎的奥秘}, \url{http://blog.csdn.net/cannel_2020/article/details/7672042}, 06/18 2012.
\bibitem{}{谱半径}, \url{http://zh.wikipedia.org/wiki/%E8%B0%B1%E5%8D%8A%E5%BE%84}.
\bibitem{}{特征向量的应用：PageRank算法Google搜索引擎的奥秘}, \url{http://f.dataguru.cn/thread-330418-1-1.html}, 07/20 2014.
\bibitem{}{检索的智化与优化，第五节 Google PageRank算法}, \url{http://chaxin.gdinfo.net/web/www/dialog/index.php/Dialog/%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0ch5_5.htm}.
\bibitem{}{姜启源},{数学模型（第三版}
\bibitem{}{PerronCFrobenius theorem}, \url{http://www.cnblogs.com/ZhangShuo/articles/1866748.html }, 10/24 2013.
\bibitem{}{Xindongwu, Vipin Kumar},{Top 10 Algorithms in Data Mining. ICDM 2006 Panel 12/21/2006}
\bibitem{}{We Recommend a Singular Value Decomposition}, \url{http://www.ams.org/samplings/feature-column/fcarc-svd }.
\bibitem{}{ccjou},{ΨQ矩可正交角化的C明}, \url{https://ccjou.wordpress.com/2011/02/09/%E5%AF%A6%E5%B0%8D%E7%A8%B1%E7%9F%A9%E9%99%A3%E5%8F%AF%E6%AD%A3%E4%BA%A4%E5%B0%8D%E8%A7%92%E5%8C%96%E7%9A%84%E8%AD%89%E6%98%8E/}, 02/09 2011.
\bibitem{}{iMetaSearch},{Latent Semantic Analysis (LSA) Tutorial },    \url{http://www.puffinwarellc.com/index.php/news-and-articles/articles/33-latent-semantic-analysis-tutorial.html?start=6}.
\end{thebibliography}
